{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Q学習で迷路を攻略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUQAAAEzCAYAAABJzXq/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXRUZZ7/8fc3G1tA+AkiBFlsVDrYLiTwA52fW7BBHbUVcYRpZVFwQdtRPPY442hrt3MURY82jG1mIO62ilvwqG1aEUZxC4goSytjg2wOIbKHkIR8f3/UhQ4hUJWQyq0qPq9z6lBV97m3vnkIH567PWXujoiIQFrYBYiIJAoFoohIQIEoIhJQIIqIBBSIIiIBBaKISCBqIJpZazP7zMy+NLMlZnZPA21amdmLZrbCzD41s97xKFZEJJ5iGSHuAs5x95OBU4DhZja4XpurgU3u3hd4BHgg2kbNbGJji00UyVp7stYNyVt7stYNyVv7odQdNRA9YnvwMjN41L+a+2LgqeD5LKDAzCzKppOyswPJWnuy1g3JW3uy1g3JW3v8AhHAzNLNbBGwAShx90/rNckBVgO4ew2wBTiyqUWJiITBGnPrnpl1BF4DbnL3r+u8vwQY5u5rgtf/Awxy9/J6608kSO9WrVrlnXjiiYf+E4SgrKyMLl26hF1GoyVr3ZC8tSdr3ZC8tS9YsGAX8HWdtwrdvTCWdTMa80HuvtnMPgCG1/vANcAxwBozywCOAH5sYP1CoBAgPz/fS0tLG/PxIiJRmdnX7p7flHVjOcvcJRgZYmZtgKHA8nrNioExwfPLgPdds0aISJKJZYTYDXjKzNKJBOhL7v6mmd0LlLp7MTADeMbMVhAZGV4Rt4pFROIkaiC6+2Lg1Abev6vO80pgZPOWJiLSsnSniohIQIEoIhJQIIqIBBSIIiIBBaKISECBKCISUCCKiAQUiCIiAQWiiEhAgSgiEmjUbDeHC3dn7ba1LFi3gM/WfsbcVXNZWraUnTU7qamtYXftbtLT0slIy6BNRhtyu+RyZq8zGZQziLzueeS0zyH6/LgikmgUiIFar+W9797j4U8e5qPvP6KmtobM9Ey2V22n1mv3a19TW0NNbQ2VNZV8tPojPl7zMdlZ2VTtriIzLZPTe57OrYNvpeDYAtJMA3GRZHDYB+KmnZuY+cVMpn48lW1V29hetX3vsp01O2PeTq3XsnXXVgAqqeSdFe/w4fcf0j6rPZOHTGb8qePp1KZTs9cvIs2nUTNmN6ewJ4hds3UNt5fczmvLXyPN0qiorojbZ7XNbEut13Jpv0t54NwH6NGhR9w+S+RwZ2YL4jZBbKpxd2Z8MYN+0/rx8pKXqaypjGsYAlRUV1BZU8lLS16i37R+zPhiBpo/VyTxHFaBuHbrWs5+6mxufvtmdlTvoMZrWvTza7yGHdU7uPntmzn7qbNZu3Vti36+iBzcYROIRYuK6DetHx+t/ogd1TtCrWVH9Q4+Wv0R/ab3o2hRUai1iMjfpHwguju3vHMLN751I9urt1NT27KjwgOpqa1he9V2bnzrRm79063ahRZJACkdiLtrdzP29bEULiyM+3HCpqqoruCJBU8w7o1x7K7dHXY5Ioe1lL3sxt0Z/8Z4Zi2blbBhuEdFdQUvL30ZgKKLi3RRt0hIUnaEeOufbuWVZa8kfBjusScUJ787OexSRA5bKRmIRYuKKFxYGPrJk8bas/usEy0i4Ui5QFy7dS2/eutXSTMyrK+iuoJfvf0rXZIjEoKUCkR3Z/Sro6ncXRl2KYdkV80u/vHVf9SZZ5EWllKBOHPRTBasW5Awl9Y0VXVtNaXrSrXrLNLCUiYQ12xds/cOlFSwo3oHN79zs3adRVpQygTi7SW3s6tmV9hlNKvKmkpuL7k97DJEDhspEYibdm7iteWvtfi9yfFWU1vDq8tfZdPOTWGXInJYSIlAnPnFzJSdhDXN0nQsUaSFJH2K1HotUz+emrSX2URTUV3B1PlTG5y1W0SaV9IH4nvfvce2qm3Nv+EdwJvAI8BvgQeBp4D/CZY7MAd4CPgdUARsaP4yALZWbeX9v74fn40nkLKyMm644QZ69+5Nq1at6Nq1KwUFBZSUlADw6quvMmzYMLp06YKZ8cEHH4RbcAo4WJ9XV1fz61//mpNOOol27drRrVs3Ro8ezffffx922XGT9PcyP/zJw/tM+99sXgSqgYuB/0MkIFcCewaiHwEfA78AjgTmAk8DNwGtmreU7VXbmfrxVIYeO7R5N5xgRowYQUVFBTNmzKBv375s2LCBuXPnUl5eDsCOHTs47bTT+OUvf8lVV10VcrWp4WB9XlFRwcKFC/nXf/1XTjnlFLZs2cLkyZMZPnw4ixcvJiMj6eNjP0n9FQLuzhH3H9H8I8SdwAPAlcBPGvpgYCowCDgjeK+ayCjy50CTJi8/uA6tOrD515tTduKHzZs306lTJ0pKShg69ODBv3HjRrp06cKcOXM466yzWqbAFNSYPt9j6dKl9O/fn8WLF/Ozn/0szhU2zWH7FQJrt62lura6+TecFTz+QiTo6tsEbGffsMwEegGrm78cgKrdVazbti4+G08A2dnZZGdnU1xcTGVlct9plCya0udbt0a+SK1Tp9T8wrSkDsQF6xaQlZ7V/BtOJ7IrvBi4H/gv4E/AmmD5nj30dvXWa1dnWTPLSs9iwfoF8dl4AsjIyODJJ5/k2WefpWPHjgwZMoTbbruNTz/9NOzSUlZj+7yqqorJkydz4YUX0qNHan5RWlIH4mdrP4vP8UOAXGAyMBroS2Tk91/AvDptWnDvdUfVDj5b+1nLfWAIRowYwbp165g9ezbnnXce8+fPZ/Dgwfz7v/972KWlrFj7vKamhl/+8pds3ryZoqLUvQwsaiCa2TFmNsfMlpnZEjO7uYE2Z5nZFjNbFDzuik+5+5q7am58L0fJJLJbfBZwDXAq8AHQNlheP4t3ANnxKWW372buqrnx2XgCad26Neeeey533XUX8+fP5+qrr+Y3v/kNVVVVYZeWsqL1eU1NDaNGjWLx4sW89957HHnkkSFXHD+xnCaqASa7+0Izaw8sMLMSd19ar91/u/vfN3+JB7a0rH4JcdYFqCUSetlELsHJCZZVA6uInFSJkxb/eRNAbm4uNTU1VFZWkpUVh8Mjsp+6fW5mXHHFFXz99dd88MEHHH300WGXF1dRA9Hd1wPrg+fbzGwZkRgI/V/nzpqd8dlwBfASkRFhVyKX0awjcqnNsUBrYDCR3efORC67mUfkREwcT7ztrI7Tz5sAysvLGTlyJOPHj+ekk06iffv2lJaWMmXKFAoKCujQoQM//vgj33//PZs3bwZgxYoVdOzYkaOPPjrl/6HGQ7Q+b9u2LZdddhmff/45s2fPxsz44YcfADjiiCNo06ZNyD9B82vUhURm1ptITDR01HWImX1JJDpuc/clh1xdFHGb5isL6EHkp/yRyBi5A5Gw23OZzelERoVvEblMpweRy3Sa+RrEuuJyRj1BZGdnM3jwYB599FFWrFjBrl27yMnJYfTo0dx5550AFBcXM27cuL3rTJgwAYC7776b3/zmN2GUndSi9fmaNWt44403AMjLy9tn3aKiIsaOHRtC1fEV83WIZpZN5PLj+9z91XrLOgC17r7dzM4HHnX34xrYxkRgIkDPnj3zVq1adUjFp92ThnP4TKJqGLV36xY+kYMxs1XAxjpvFbp7YSzrxjRCNLNM4BXgufphCODuW+s8f8vM/sPMOrv7xnrtCoFCiFyYHctnH0x6WnrSTwbbGOlp6WGXIJIMNsbtwmyL3BoxA1jm7g8foM3RQTvMbFCw3fKmFNQYGWmpd+vQwWSmZYZdgkhKiyVRTidydOwrM1sUvPcvQE8Ad/8DcBlwvZnVEDmidoW3wD2BbTLaUFlz+NzV0CYz9Q5iiySSWM4yf0iUS5DdfRowrbmKilVul1w+Wv1RS39saHK75IZdgkhKS+o7Vc7sdWbKTgxbX7qlc2avM8MuQySlJXWaDMoZRHZWnG4NSTDtstoxKGdQ2GWIpLSkDsS87nlU7T48bumq2l1FXre86A1FpMmSOhBz2uccNmdes9Kz6N6+e9hliKS0pA5EM+P0nqeHXUaLOO2Y01J2cliRRJHUgQhw6+BbU/44YnZWNpOHTA67DJGUl/RXNhccW0D7rPaNnxdxHvAVkQuKDGhD5ArKKiKTO3QM2l1A5IrLHUS+NuB89v2KgEf42/3LbYBLiNwL/VTw3nYi/+3smTJsAo3u9Q6tOnBOn3Mat5KINFrSB2KapTF5yGTu+uCu2L+KdDXwDXAtkR7YAewmMoHDX4H5wD/WW2cJkQkcvmL/70wZQ2S27DlEgvYi4Ppg2RwiAdnEPfu2mW2ZPGTyYXN5kUiYUuJf2fhTxzduothtREZse/47aEckDA/mayJzHW4NHg3pcZBlTVTrtYw7ZVz0hiJyyFIiEDu16cQl/S4hw2Ic8P4E2AI8RuS7l1dGab+FyK5vD6A/kXBsyAqgX2wlxCIjLYNL+11Kpzap+YU+IokmJQIRYMq5U2iVEeNkhK2I7C5fSGR0+DLwxUHaf00kCAFOZP9AfAqYAnxHs04Q2zqjNVPOndJ8GxSRg0qZQOzRoQePnvco7TLrfxXeAaQBfYCziZwoWXaQtl8Bi4icQHkB+IF95/IZA9wCHEXkmGEzaJfZjkeHP0pOh5zojUWkWaRMIAKMP2U8+d3zo08LtpF9A+0H4IiDtK0m8g18twSP/8f+o8RMYDjwJZGz1IcgMy2TgTkDdexQpIWlVCCaGc9d+hyt01sfvGEV8BqR+Xn+Aygj8s16DfmK/Y8L/jR4v772RHaZP4+55Aa1ymjFs5c8qwuxRVpYzF8h0Nzy8/O9tLQ0LtsuWlTEjW/dGPtlOAmkbWZbpp0/TaNDkSYyswVxmzE7GY07ZRwTB0ykbWbb6I0TSLvMdlybd63CUCQkKRmIAA8Pe5jLfnpZ0oRi28y2XJZ7GVN/PjXsUkQOWykbiGbGzItnMjJ3ZMKHYtvMtozMHcmMi2bouKFIiFI2ECHyLXVFFxdxbd61CRuKbTPbcl3edRRdXKRv1RMJWUoHIkRGig8Pe5hp508jOys7Yb6pLzMtk+ysbKadP42pw6ZqZCiSAFI+EPcYd8o4lk9azunHnB77xdtx0i6zHacdcxrLJy3XCRSRBHLYBCJATocc5oyZw2PnPRYZLcZ673MzyUjLIDsrm8fOe4w5Y+boLhSRBHNYBSJEdqHHnzqeZZOWcXn/y2md0Zq2GfE9vtg2oy2tM1pzee7lLJ+0nPGnjtcuskgCSowDaiHo0aEHz414jk07N1G0qIiH5j/EtqptjZ9o9iCys7LpkNWByadNZtwp4zRrjUiCS8k7VZqi1mt5/6/vM/XjqcxfPZ+q3VVkpWexvWp7THMtplka2VnZe9c77ZjTmDxkMuf0OUeTu4q0oEO5U+WwHSHWl2ZpDD12KEOPHYq7s27bOhasX8Bnaz9j7qq5LC1bys7qnVTXVrO7djfpaelkpmXSJrMNuV1yObPXmQzKGURetzy6t++uXWKRJKRAbICZkdMhh5wOOVx0wkVhlyMiLUT7ciIiAQWiiEhAgSgiElAgiogEFIgiIgEFoohIQIEoIhJQIIqIBBSIIiIBBaKISCBqIJrZMWY2x8yWmdkSM7u5gTZmZo+Z2QozW2xmA+JTrohI/MRyL3MNMNndF5pZe2CBmZW4+9I6bc4Djgse/xd4PPhTRCRpRB0huvt6d18YPN8GLAPqT/V8MfC0R3wCdDSzbs1erYhIHDVqthsz6w2cCnxab1EOsLrO6zXBe+sPoTZpTpqOLDwhzTkqjRfzSRUzywZeAf7J3bfWX9zAKvv9FpjZRDMrNbPSsrKyxlUqIhKbzntyJnhMjHXFmEaIZpZJJAyfc/dXG2iyBjimzusewLr6jdy9ECiEyIzZsRYpzUCjlJanUXlYNjZ1xuxYzjIbMANY5u4PH6BZMXBVcLZ5MLDF3bW7LCJJJZYR4unAlcBXZrYoeO9fgJ4A7v4H4C3gfGAFUAHoy4ZFJOlEDUR3/5CGjxHWbePApOYqSkQkDLpTRUQkoEAUEQkoEEVEAgpEEZGAAlFEJKBAFBEJKBBFRAIKRBGRgAJRRCSgQBQRCSgQRUQCCkQRkYACUUQkoEAUEQkoEEVEAgpEEZGAAlFEJKBAFBEJKBBFRAIKRBGRgAJRRCSgQBQRCSgQRUQCCkQRkYACUUQkoEAUEQkoEEVEAgpEEZGAAlFEJKBAFBEJKBAPoKysjBtuuIHevXvTqlUrunbtSkFBASUlJQD827/9G/369aNdu3Z06tSJgoIC5s+fH3LVyS1an9c1ceJEzIyHHnoohEpTR7Q+Hzt2LGa2z2Pw4MEhVx0/GWEXkKhGjBhBRUUFM2bMoG/fvmzYsIG5c+dSXl4OwAknnMD06dPp06cPO3fu5JFHHmH48OF8++23dO3aNeTqk1O0Pt9j1qxZfP7553Tv3j2kSlNHLH0+dOhQnnnmmb2vs7Kywii1Zbh7KI+8vDxPVJs2bXLAS0pKYl5ny5YtDvg777wTx8pSV6x9vnLlSu/evbsvXbrUe/Xq5Q8++GALVdgEEHkkqFj6fMyYMX7BBRe0YFWHDij1JuaSdpkbkJ2dTXZ2NsXFxVRWVkZtX1VVRWFhIR06dOCUU05pgQpTTyx9XlNTw6hRo7jzzjv56U9/2sIVpp5Yf88//PBDjjrqKI4//ngmTJjAhg0bWrDKlqVAbEBGRgZPPvkkzz77LB07dmTIkCHcdtttfPrpp/u0e/PNN8nOzqZ169Y88sgjlJSUaHe5iWLp87vvvpsjjzyS66+/PsRKU0csfT58+HCefvpp3nvvPaZOncpnn33GOeecw65du0KsPI6aOrQ81Eci7zLvsXPnTn/33Xf9nnvu8SFDhjjg9913397l27dv92+//dY//vhjHz9+vPfq1cvXrVsXYsXJ70B9/sEHH3j37t19w4YNe9tql7l5RPs9r2vt2rWekZHhr7zySgtXGTsOYZc5egOYCWwAvj7A8rOALcCi4HFXLB+cDIFY39VXX+2ZmZm+a9euBpf37dvX77333hauKrXt6fM77rjDzczT09P3PgBPS0vznJycsMtsWJIEYn3Rfs979+7t999/fwtXFbtDCcRYzjI/CUwDnj5Im/92979vygg1meTm5lJTU0NlZWWDZ9pqa2tTd1ciJHv6/LrrrmP06NH7LBs2bBijRo1iwoQJIVWXmg72e75x40bWrl1Lt27dQqouvqIGorvPM7Pe8S8lcZSXlzNy5EjGjx/PSSedRPv27SktLWXKlCkUFBQAcOedd3LhhRfSrVs3ysrKmD59OmvWrOHyyy8PufrkFK3Pe/bsud86mZmZHH300ZxwwgkhVJz8ovV5Wloat912GyNGjKBbt26sXLmSO+64g6OOOopLLrkk7PLjormuQxxiZl8C64Db3H1JM203FNnZ2QwePJhHH32UFStWsGvXLnJychg9ejR33nknGRkZLFmyhJkzZ1JeXs6RRx7JwIEDmTdvHieddFLY5SelaH0uzS9an6enp/PVV1/x9NNPs3nzZrp168bZZ5/NSy+9RPv27cMuPy4ssssdpVFkhPimu5/YwLIOQK27bzez84FH3f24A2xnIjARoGfPnnmrVq06hNJFEpxZ5M8Y/o1J8zGzVcDGOm8VunthLOse8gjR3bfWef6Wmf2HmXV2940NtC0ECgHy8/P1WyIi8bDR3fObsuIhX4doZkebRf4rNLNBwTbLD76WiEjiiTpCNLMXiFxa09nM1gB3A5kA7v4H4DLgejOrAXYCV3gs++EiIgkmlrPMo6Isn0bkshwRkaSmW/dERAIKRBGRgAJRRCSgQBQRCSgQRUQCCkQRkYACUUQkoEAUEQkoEEVEAgpEEZGAAlFEJKBAFBEJKBBFRAIKRBGRgAJRRCSgQBQRCSgQRUQCCkQRkYACUUQkoEAUEQkoEEVEAgpEEZGAAlFEJKBAFBEJKBBFRAIKRBGRgAJRRCSgQBQRCSgQRUQCCkQRkYACUUQkoEAUEQkoEEVEAgpEEZGAAlFEJKBAFBEJRA1EM5tpZhvM7OsDLDcze8zMVpjZYjMb0PxliojEXywjxCeB4QdZfh5wXPCYCDx+6GWJiLS8qIHo7vOAHw/S5GLgaY/4BOhoZt2aq0ARkZaS0QzbyAFW13m9JnhvfTNsW5qLWeRP93DrOBzt6XtJeM1xUqWhv+0G/9WZ2UQzKzWz0rKysmb4aBGR/XTekzPBY2KsKzbHCHENcEyd1z2AdQ01dPdCoBAgPz9fQxVJbRqNh8Nso7vnN2XV5hghFgNXBWebBwNb3F27yyKSdKKOEM3sBeAsIsPQNcDdQCaAu/8BeAs4H1gBVADj4lWsiEg8RQ1Edx8VZbkDk5qtIhGRkOhOFRGRgAJRRCSgQBQRCSgQRUQCCkQRkYACUUQkoEAUEQkoEEVEAgpEEZGAAlFEJKBAFBEJKBBFRAIKRBGRgAJRRCSgQBQRCSgQRUQCCkQRkYACUUQkoEAUEQkoEEVEAgpEEZGAAlFEJKBAFBEJKBBFRAIKRBGRgAJRRCSgQBQRCSgQRUQCCkQRkYACUUQkoEAUEQkoEA+grKyMG264gd69e9OqVSu6du1KQUEBJSUle9t88803XHrppXTs2JG2bdsyYMAAli1bFmLVyS1an5tZg49JkyaFXHnyitbn27dv56abbqJHjx60adOGE044gUceeSTkquMnI+wCEtWIESOoqKhgxowZ9O3blw0bNjB37lzKy8sB+Otf/8rpp5/OVVddxfvvv0/Hjh1Zvnw52dnZIVeevKL1+fr16/dpX1payoUXXsjll18eRrkpIVqf33rrrfz5z3/mmWeeoU+fPsybN48JEybQuXNnrrzyypCrjwN3D+WRl5fniWrTpk0OeElJyQHbjBo1ykePHt2CVR0iiDwSVCx9Xt8111zjxx9/fByrSm2x9Hn//v39rrvu2ue9M844wydNmhTv8poMKPUm5pJ2mRuQnZ1NdnY2xcXFVFZW7re8traW2bNnk5uby/Dhw+nSpQsDBw7kxRdfDKHa1BCtz+vbtm0bf/zjH5kwYUILVJeaYunzv/u7v2P27NmsXr0agPnz57No0SKGDx/ekqW2nKYm6aE+EnmE6O4+a9Ys79Spk7dq1coHDx7skydP9k8++cTd3devX++At23b1qdOnepffPGFT5061dPT03327NkhV34ACT5CdD94n9f3xBNPeGZmpm/YsKGFq0wt0fp8165dPm7cOAc8IyPDMzIy/PHHHw+x4ug4hBGiAvEgdu7c6e+++67fc889PmTIEAf8vvvu87Vr1zrgo0aN2qf9qFGjfPjw4SFVG0USBKL7gfu8vvz8fB85cmQIFaaeg/X5Qw895Mcff7wXFxf7l19+6b///e+9Xbt2/vbbb4dc9YHFPRCB4cBfgBXAPzewfCxQBiwKHtdE22YyBGJ9V199tWdmZvquXbs8IyPDf/vb3+6z/N577/Xc3NyQqosiSQKxvrp9vscXX3zhgL/77rshVpa69vT55s2bPTMz019//fX9lhcUFIRUXXSHEohRzzKbWTowHTgXWAN8bmbF7r60XtMX3f3GQ9p/T3C5ubnU1NRQWVnJwIED+ctf/rLP8m+++YZevXqFVF1qqtvnWVlZABQWFtK7d2+GDh0acnWpaU+fmxnV1dWkp6fvszw9PZ3a2tqQqouzaIkJDAH+VOf1HcAd9dqMBaY1JokTeYS4ceNGP/vss/2ZZ57xL7/80r/77jt/6aWXvGvXrj506FB3d3/ttdc8MzPTn3jiCf/222+9sLDQMzIy/M033wy5+gNI8BFiLH3u7r5jxw7v0KGD/+53vwux2tQQS5+feeaZ3r9/f58zZ45/9913XlRU5K1bt/bHHnss5OoPjHjuMgOXAf9V5/WV9cMvCMT1wGJgFnBMtO0mciBWVlb6HXfc4fn5+d6xY0dv06aN9+3b12+55RYvLy/f266oqMiPO+44b926tf/sZz/z559/PsSqo0jwQIy1z2fOnOnp6em+du3aEKtNDbH0+fr1633s2LHevXt3b926tZ9wwgn+4IMPem1tbcjVH9ihBKJF1j8wMxsJDHP3a4LXVwKD3P2mOm2OBLa7+y4zuw643N3PaWBbE4GJAD179sxbtWpVo0e00kRmkT+j/H2LJDszWwVsrPNWobsXxrJuLHeqrAGOqfO6B7CubgN3L6/z8j+BBxraUFBUIUB+fr7+ZYpIPGx09/ymrBjLhdmfA8eZWR8zywKuAIrrNjCzbnVeXgTohl4RSTpRR4juXmNmNwJ/AtKBme6+xMzuJbKvXgz8yswuAmqAH4kcUxQRSSpRjyHGS35+vpeWloby2YclHUOUw4SZLYjnLrOIyGFBgSgiElAgiogEFIgiIgEFoohIQIEochj43//9X0aPHs2xxx5LXl4eQ4YM4bXXXgPgww8/ZNCgQfTr149+/fpRWLj/TR0nn3wyo0aN2ue9sWPHMmvWrBapv6XoO1VEUpy784tf/IIxY8bw/PPPA7Bq1SqKi4v54YcfGD16NK+//joDBgxg48aNDBs2jJycHC644AIAli1bRm1tLfPmzWPHjh20a9cuzB8nrjRCFElx77//PllZWVx33XV73+vVqxc33XQT06dPZ+zYsQwYMACAzp07M2XKFO6///69bZ9//nmuvPJKfv7zn1NcXLzf9lOJAlEkxS1ZsmRv4DW0LC8vb5/38vPzWbJkyd7XL774Iv/wD//AqFGjeOGFF+Jaa9gUiCKHmUmTJnHyySczcODAyJRXe+5iqmPPe59//jldunShV69eFBQUsHDhQjZt2tTSJbcYBaJIiuvfvz8LFy7c+3r69Om89957lJWV0b9/f+rfQrtgwQJyc3MBeOGFF1i+fDm9e/fmJz/5CVu3buWVV15p0fpbkgJRJMWdc845VFZW8vjjj+99r6KiAoiMFp988kkWLVoEQHl5Ob/+9a+5/fbbqa2t5eWXX2bx4sWsXLmSlStX8sYbb6T0brMCUSTFmRmvv/46c+fOpU+fPgwaNLlBDO4AAAUoSURBVIgxY8bwwAMP0K1bN5599lkmTJhAv379OO200xg/fjwXXngh8+bNIycnh5ycnL3bOuOMM1i6dCnr168H4Nprr6VHjx706NGDIUOGhPUjNhvNdnO40Gw3cpjQbDciIs1AgSgiElAgiogEFIgiIgEFoohIQIEoIhJQIIqIBBSIIiIBBaKISECBKCISUCCKiAQUiCIiAQWiiEhAgSgiElAgiogEFIgiIgEFoohIQIEoIhJQIIqIBBSIIiIBBaKISECBKCISiCkQzWy4mf3FzFaY2T83sLyVmb0YLP/UzHo3d6EiIvEWNRDNLB2YDpwH5AKjzCy3XrOrgU3u3hd4BHiguQsVEYm3WEaIg4AV7v6du1cBfwQurtfmYuCp4PksoMBszzeji4gkh1gCMQdYXef1muC9Btu4ew2wBTiyOQoUEWkpGTG0aWik501og5lNBCYGL3eZ2dcxfH4i6gxsDLuIJuiMWTLWDcnc58lZNyRv7SeaWWmd14XuXhjLirEE4hrgmDqvewDrDtBmjZllAEcAP9bfUFBUIYCZlbp7fixFJppkrT1Z64bkrT1Z64bkrf1Q6o5ll/lz4Dgz62NmWcAVQHG9NsXAmOD5ZcD77r7fCFFEJJFFHSG6e42Z3Qj8CUgHZrr7EjO7Fyh192JgBvCMma0gMjK8Ip5Fi4jEQyy7zLj7W8Bb9d67q87zSmBkIz87pn36BJWstSdr3ZC8tSdr3ZC8tTe5btOerYhIhG7dExEJxD0Qk/W2vxjqHmtmZWa2KHhcE0ad9ZnZTDPbcKBLmiziseDnWmxmA1q6xgOJofazzGxLnT6/q6F2Lc3MjjGzOWa2zMyWmNnNDbRJuH6Pse5E7fPWZvaZmX0Z1H5PA20any3uHrcHkZMw/wMcC2QBXwK59drcAPwheH4F8GI8a2rGuscC08KutYHazwAGAF8fYPn5wNtErh0dDHwads2NqP0s4M2w62ygrm7AgOB5e+CbBn5fEq7fY6w7UfvcgOzgeSbwKTC4XptGZ0u8R4jJettfLHUnJHefRwPXgNZxMfC0R3wCdDSzbi1T3cHFUHtCcvf17r4weL4NWMb+d3MlXL/HWHdCCvpxe/AyM3jUPyHS6GyJdyAm621/sdQNMCLY/ZllZsc0sDwRxfqzJaohwW7S22bWP+xi6gt2y04lMmKpK6H7/SB1Q4L2uZmlm9kiYANQ4u4H7PNYsyXegdhst/21sFhqmg30dveTgD/zt/+JEl0i9nesFgK93P1k4PfA6yHXsw8zywZeAf7J3bfWX9zAKgnR71HqTtg+d/fd7n4KkbvnBpnZifWaNLrP4x2Ijbntj4Pd9tfCotbt7uXuvit4+Z9AXgvVdqhi+TtJSO6+dc9ukkeujc00s84hlwWAmWUSCZXn3P3VBpokZL9HqzuR+3wPd98MfAAMr7eo0dkS70BM1tv+otZd7/jPRUSOvySDYuCq4KznYGCLu68Pu6hYmNnRe44BmdkgIr+/5eFWFTmDTORurWXu/vABmiVcv8dSdwL3eRcz6xg8bwMMBZbXa9bobInpTpWm8iS97S/Gun9lZhcBNUTqHhtawXWY2QtEzgx2NrM1wN1EDjjj7n8gcsfR+cAKoAIYF06l+4uh9suA682sBtgJXJEA/3kCnA5cCXwVHNMC+BegJyR0v8dSd6L2eTfgKYtMYJ0GvOTubx5qtuhOFRGRgO5UEREJKBBFRAIKRBGRgAJRRCSgQBQRCSgQRUQCCkQRkYACUUQk8P8BirtPkk7R/vEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#迷宫的初始位置\n",
    "\n",
    "#声明图的大小以及图的变量名\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "#画出红色的墙壁\n",
    "plt.plot([1, 1], [0, 1], color='red', linewidth=2)\n",
    "plt.plot([1, 2], [2, 2], color='red', linewidth=2)\n",
    "plt.plot([2, 2], [2, 1], color='red', linewidth=2)\n",
    "plt.plot([2, 3], [1, 1], color='red', linewidth=2)\n",
    "\n",
    "#画出表示状态的文字S0-S8\n",
    "plt.text(0.5, 2.5, 'S0', size=14, ha='center')\n",
    "plt.text(1.5, 2.5, 'S1', size=14, ha='center')\n",
    "plt.text(2.5, 2.5, 'S2', size=14, ha='center')\n",
    "plt.text(0.5, 1.5, 'S3', size=14, ha='center')\n",
    "plt.text(1.5, 1.5, 'S4', size=14, ha='center')\n",
    "plt.text(2.5, 1.5, 'S5', size=14, ha='center')\n",
    "plt.text(0.5, 0.5, 'S6', size=14, ha='center')\n",
    "plt.text(1.5, 0.5, 'S7', size=14, ha='center')\n",
    "plt.text(2.5, 0.5, 'S8', size=14, ha='center')\n",
    "plt.text(0.5, 2.3, 'START', ha='center')\n",
    "plt.text(2.5, 0.3, 'GOAL', ha='center')\n",
    "\n",
    "#设定画图的范围\n",
    "ax.set_xlim(0, 3)\n",
    "ax.set_ylim(0, 3)\n",
    "plt.tick_params(axis='both', which='both', bottom='off', top='off',\n",
    "                labelbottom='off', right='off', left='off', labelleft='off')\n",
    "\n",
    "#当前位置S0用绿色圆圈画出\n",
    "line, = ax.plot([0.5], [2.5], marker=\"o\", color='g', markersize=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设定参数θ的初始值theta_0，用于确定初始方案\n",
    "\n",
    "#行为状态0-7，列为↑，→，↓，←表示的移动方向\n",
    "theta_0 = np.array([[np.nan, 1, 1, np.nan],  # s0\n",
    "                    [np.nan, 1, np.nan, 1],  # s1\n",
    "                    [np.nan, np.nan, 1, 1],  # s2\n",
    "                    [1, 1, 1, np.nan],  # s3\n",
    "                    [np.nan, np.nan, 1, 1],  # s4\n",
    "                    [1, np.nan, np.nan, np.nan],  # s5\n",
    "                    [1, np.nan, np.nan, np.nan],  # s6\n",
    "                    [1, 1, np.nan, np.nan],  # s7、※s8是目标，无策略\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将策略参数theta_0转换为随机策略\n",
    "\n",
    "\n",
    "def simple_convert_into_pi_from_theta(theta):\n",
    "    '''简单计算比率'''\n",
    "\n",
    "    [m, n] = theta.shape  # 读取theta矩阵的大小\n",
    "    pi = np.zeros((m, n))\n",
    "    for i in range(0, m):\n",
    "        pi[i, :] = theta[i, :] / np.nansum(theta[i, :])  # 计算比率\n",
    "\n",
    "    pi = np.nan_to_num(pi)  # 将nan转换为0\n",
    "\n",
    "    return pi\n",
    "\n",
    "# 求取随机行动策略\n",
    "pi_0 = simple_convert_into_pi_from_theta(theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置初始的动作价值函数\n",
    "'''以上的代码和前面完全相同。由于不知道正确的动作价值，因此对初始状态赋予随机值'''\n",
    "[a, b] = theta_0.shape  # 行と列の数をa, bに格納\n",
    "Q = np.random.rand(a, b) * theta_0*0.1\n",
    "# 将theta_0乘到各元素上，使得Q的墙壁方向的值为nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现ε-贪婪法\n",
    "\n",
    "\n",
    "def get_action(s, Q, epsilon, pi_0):\n",
    "    direction = [\"up\", \"right\", \"down\", \"left\"]\n",
    "\n",
    "    # 确定行动\n",
    "    if np.random.rand() < epsilon:\n",
    "        # 以ε概率随机行动\n",
    "        next_direction = np.random.choice(direction, p=pi_0[s, :])\n",
    "    else:\n",
    "        # 采用Q的最大值对应的动作\n",
    "        next_direction = direction[np.nanargmax(Q[s, :])]\n",
    "\n",
    "    # 为动作加上索引\n",
    "    if next_direction == \"up\":\n",
    "        action = 0\n",
    "    elif next_direction == \"right\":\n",
    "        action = 1\n",
    "    elif next_direction == \"down\":\n",
    "        action = 2\n",
    "    elif next_direction == \"left\":\n",
    "        action = 3\n",
    "\n",
    "    return action\n",
    "\n",
    "\n",
    "def get_s_next(s, a, Q, epsilon, pi_0):\n",
    "    direction = [\"up\", \"right\", \"down\", \"left\"]\n",
    "    next_direction = direction[a]  # 动作a对应的方向\n",
    "\n",
    "    # 由动作确定下一个状态\n",
    "    if next_direction == \"up\":\n",
    "        s_next = s - 3  # 向上移动时，状态数减3\n",
    "    elif next_direction == \"right\":\n",
    "        s_next = s + 1  # 向右移动时，状态数加1\n",
    "    elif next_direction == \"down\":\n",
    "        s_next = s + 3  # 向下移动时，状态数加3\n",
    "    elif next_direction == \"left\":\n",
    "        s_next = s - 1  # 向左移动时，状态数减1\n",
    "\n",
    "    return s_next\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q学习的Q更新公式是：$Q(s_t,a_t)=Q(s_t,a_t)+\\eta*(R_{t+1}+\\gamma*\\max_{a}Q(s_{t+1},a)-Q(s_t,a_t))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于Q学习的动作价值函数Q的更新\n",
    "\n",
    "\n",
    "def Q_learning(s, a, r, s_next, Q, eta, gamma):\n",
    "\n",
    "    if s_next == 8:  # 到达目标时\n",
    "        Q[s, a] = Q[s, a] + eta * (r - Q[s, a])\n",
    "\n",
    "    else:\n",
    "        Q[s, a] = Q[s, a] + eta * (r + gamma * np.nanmax(Q[s_next,: ]) - Q[s, a])\n",
    "\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义基于Q学习求解迷宫问题的函数，输出状态，动作的历史记录以及更新后的Q\n",
    "\n",
    "\n",
    "def goal_maze_ret_s_a_Q(Q, epsilon, eta, gamma, pi):\n",
    "    s = 0  # 开始地点\n",
    "    a = a_next = get_action(s, Q, epsilon, pi)  # 初始动作\n",
    "    s_a_history = [[0, np.nan]]  # 记录智能体的移动序列\n",
    "\n",
    "    while (1):  # 循环直到到达目标\n",
    "        a = a_next  # 跟新动作\n",
    "\n",
    "        s_a_history[-1][1] = a\n",
    "        # 将动作放在现在的状态下（最终的index=-1）\n",
    "\n",
    "        s_next = get_s_next(s, a, Q, epsilon, pi)\n",
    "        # 有效的下一个状态\n",
    "\n",
    "        s_a_history.append([s_next, np.nan])\n",
    "        # 代入下一个状态，动作未知时为nan\n",
    "\n",
    "        # 给予奖励，求得下一个动作\n",
    "        if s_next == 8:\n",
    "            r = 1  # 达到目标，给予奖励\n",
    "            a_next = np.nan\n",
    "        else:\n",
    "            r = 0\n",
    "            a_next = get_action(s_next, Q, epsilon, pi)\n",
    "            # 求得下一个动作a_next\n",
    "\n",
    "        # 更新价值函数\n",
    "        Q = Q_learning(s, a, r, s_next, Q, eta, gamma)\n",
    "\n",
    "        # 终止判断\n",
    "        if s_next == 8:  # 到达目的地则结束\n",
    "            break\n",
    "        else:\n",
    "            s = s_next\n",
    "\n",
    "    return [s_a_history, Q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前回合:1\n",
      "0.0006977890772398299\n",
      "求解迷宫问题所需步数6\n",
      "当前回合:2\n",
      "0.06206174760467234\n",
      "求解迷宫问题所需步数6\n",
      "当前回合:3\n",
      "0.0004944817814270808\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:4\n",
      "0.0004560754525554378\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:5\n",
      "0.00042059875955369197\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:6\n",
      "0.00038783207619319526\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:7\n",
      "0.0003575720257220638\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:8\n",
      "0.0003296302807371809\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:9\n",
      "0.0003038324536813741\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:10\n",
      "0.0002800170706845906\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:11\n",
      "0.0002580346221271457\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:12\n",
      "0.000237746683873441\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:13\n",
      "0.00021902510366267336\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:14\n",
      "0.00020175124760690721\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:15\n",
      "0.00018581530218197972\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:16\n",
      "0.00017111562747651465\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:17\n",
      "0.00015755815781937077\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:18\n",
      "0.00014505584622181988\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:19\n",
      "0.00013352814935641\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:20\n",
      "0.00012290055005914624\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:21\n",
      "0.00011310411457787772\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:22\n",
      "0.00010407508201026872\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:23\n",
      "9.575448356813343e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:24\n",
      "8.808778949076501e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:25\n",
      "8.102458159320314e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:26\n",
      "7.451824958759623e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:27\n",
      "6.852570945925507e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:28\n",
      "6.300714229734439e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:29\n",
      "5.7925752113718865e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:30\n",
      "5.3247541272449794e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:31\n",
      "4.894110227116055e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:32\n",
      "4.497742469400379e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:33\n",
      "4.132971624981607e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:34\n",
      "3.7973236880151084e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:35\n",
      "3.48851450019394e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:36\n",
      "3.20443550119176e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:37\n",
      "2.9431405245028408e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:38\n",
      "2.7028335632506284e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:39\n",
      "2.481857436509305e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:40\n",
      "2.278683291156991e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:41\n",
      "2.0919008790643012e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:42\n",
      "1.9202095535852948e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:43\n",
      "1.7624099336144283e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:44\n",
      "1.617396186570641e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:45\n",
      "1.484148885810832e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:46\n",
      "1.3617284005174035e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:47\n",
      "1.249268779357493e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:48\n",
      "1.1459720922535332e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:49\n",
      "1.0511031963367223e-05\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:50\n",
      "9.639848954634544e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:51\n",
      "8.839934643734004e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:52\n",
      "8.10554510599637e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:53\n",
      "7.431391493284423e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:54\n",
      "6.812604682604473e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:55\n",
      "6.244702609681241e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:56\n",
      "5.72356008743391e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:57\n",
      "5.245380927831889e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:58\n",
      "4.806672192270156e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:59\n",
      "4.404220416254212e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:60\n",
      "4.03506965596101e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:61\n",
      "3.6965012242262674e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:62\n",
      "3.386014988282504e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:63\n",
      "3.101312109232701e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:64\n",
      "2.8402791185655474e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:65\n",
      "2.60097322923869e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:66\n",
      "2.381608785295697e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:67\n",
      "2.1805447678602263e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:68\n",
      "1.9962732746847678e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:69\n",
      "1.8274088993130988e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:70\n",
      "1.672678941133654e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:71\n",
      "1.5309143850394946e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:72\n",
      "1.4010415863019432e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:73\n",
      "1.2820746134734051e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:74\n",
      "1.173108192142891e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:75\n",
      "1.0733112082439433e-06\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:76\n",
      "9.819207235084448e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:77\n",
      "8.982364677612154e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:78\n",
      "8.216157650897671e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:79\n",
      "7.514688676879544e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:80\n",
      "6.872546584046901e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:81\n",
      "6.284766975728218e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:82\n",
      "5.746795869177035e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:83\n",
      "5.254456216796655e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:84\n",
      "4.803917144080572e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:85\n",
      "4.3916656544684685e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:86\n",
      "4.0144805835140573e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:87\n",
      "3.6694087002242526e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:88\n",
      "3.353742683565031e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:89\n",
      "3.065000929725059e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:90\n",
      "2.800908963651594e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:91\n",
      "2.559382368261254e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:92\n",
      "2.3385110958784594e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:93\n",
      "2.1365450619814652e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:94\n",
      "1.9518809202256904e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:95\n",
      "1.7830498866278077e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:96\n",
      "1.6287065940367995e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:97\n",
      "1.487618839224325e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:98\n",
      "1.3586581670832487e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:99\n",
      "1.240791245304962e-07\n",
      "求解迷宫问题所需步数4\n",
      "当前回合:100\n",
      "1.1330719285052027e-07\n",
      "求解迷宫问题所需步数4\n"
     ]
    }
   ],
   "source": [
    "# 通过Q学习求解迷宫问题\n",
    "\n",
    "eta = 0.1  # 学习率\n",
    "gamma = 0.9  # 时间折扣率\n",
    "epsilon = 0.5  # ε-greedy法的初始值\n",
    "v = np.nanmax(Q, axis=1)  # 根据状态求价值的最大\n",
    "is_continue = True\n",
    "episode = 1\n",
    "\n",
    "V=[] #存放每回合的状态价值\n",
    "V.append(np.nanmax(Q,axis=1)) #求各个状态下动作价值的最大值\n",
    "\n",
    "while is_continue:  # 循环直到is_continue为False\n",
    "    print(\"当前回合:\" + str(episode))\n",
    "\n",
    "    # ε-greedy的値逐渐减少\n",
    "    epsilon = epsilon / 2\n",
    "\n",
    "    # 通过Q学习求解迷宫问题，求取移动历史和更新后的Q值\n",
    "    [s_a_history, Q] = goal_maze_ret_s_a_Q(Q, epsilon, eta, gamma, pi_0)\n",
    "\n",
    "    # 状态价值的变化\n",
    "    new_v = np.nanmax(Q, axis=1)  # 各状态求得最大价值\n",
    "    print(np.sum(np.abs(new_v - v)))  # 输出状态价值的变化\n",
    "    v = new_v\n",
    "    V.append(v) #添加该回合终止时的状态价值函数\n",
    "\n",
    "    print(\"求解迷宫问题所需步数\" + str(len(s_a_history) - 1) )\n",
    "\n",
    "    # 重复100回合\n",
    "    episode = episode + 1\n",
    "    if episode > 100:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过Sarsa求解迷宫问题\n",
    "\n",
    "eta = 0.1  # 学习率\n",
    "gamma = 0.9  # 时间折扣率\n",
    "epsilon = 0.5  # ε-greedy法的初始值\n",
    "v = np.nanmax(Q, axis=1)  # 根据状态求价值的最大\n",
    "is_continue = True\n",
    "episode = 1\n",
    "\n",
    "while is_continue:  # 循环直到is_continue为False\n",
    "    print(\"当前回合:\" + str(episode))\n",
    "\n",
    "    # ε-greedy的値逐渐减少\n",
    "    epsilon = epsilon / 2\n",
    "\n",
    "    # 通过Sarsa求解迷宫问题，求取移动历史和更新后的Q值\n",
    "    [s_a_history, Q] = goal_maze_ret_s_a_Q(Q, epsilon, eta, gamma, pi_0)\n",
    "\n",
    "    # 状态价值的变化\n",
    "    new_v = np.nanmax(Q, axis=1)  # 各状态求得最大价值\n",
    "    print(np.sum(np.abs(new_v - v)))  # 输出状态价值的变化\n",
    "    v = new_v\n",
    "\n",
    "    print(\"求解迷宫问题所需步数\" + str(len(s_a_history) - 1) )\n",
    "\n",
    "    # 重复100回合\n",
    "    episode = episode + 1\n",
    "    if episode > 100:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
